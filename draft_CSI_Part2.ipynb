{"cells":[{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","# Step 1: Load the training and test data\n","train_data = pd.read_csv(\"training-part-2.csv\")\n","test_data = pd.read_csv(\"test-part-2.csv\")\n","\n","# Step 2: Separate the feature vectors and classes\n","train_features = train_data.iloc[:, :-1].values\n","train_classes = train_data.iloc[:, -1].values\n","test_features = test_data.iloc[:, :-1].values\n","test_classes = test_data.iloc[:, -1].values"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>AU01_r</th>\n","      <th>AU02_r</th>\n","      <th>AU04_r</th>\n","      <th>AU05_r</th>\n","      <th>AU06_r</th>\n","      <th>AU07_r</th>\n","      <th>AU09_r</th>\n","      <th>AU10_r</th>\n","      <th>AU12_r</th>\n","      <th>AU14_r</th>\n","      <th>AU15_r</th>\n","      <th>AU17_r</th>\n","      <th>AU20_r</th>\n","      <th>AU23_r</th>\n","      <th>AU25_r</th>\n","      <th>AU26_r</th>\n","      <th>AU45_r</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.83</td>\n","      <td>2.59</td>\n","      <td>0.00</td>\n","      <td>0.92</td>\n","      <td>0.00</td>\n","      <td>1.21</td>\n","      <td>0.00</td>\n","      <td>0.15</td>\n","      <td>1.37</td>\n","      <td>2.53</td>\n","      <td>0.00</td>\n","      <td>0.45</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.83</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.05</td>\n","      <td>0.84</td>\n","      <td>0.00</td>\n","      <td>1.30</td>\n","      <td>2.05</td>\n","      <td>2.07</td>\n","      <td>2.07</td>\n","      <td>0.94</td>\n","      <td>0.00</td>\n","      <td>1.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.00</td>\n","      <td>0.22</td>\n","      <td>1.52</td>\n","      <td>1.20</td>\n","      <td>0.57</td>\n","      <td>0.00</td>\n","      <td>0.71</td>\n","      <td>1.28</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.66</td>\n","      <td>0.20</td>\n","      <td>0.00</td>\n","      <td>0.19</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.44</td>\n","      <td>0.00</td>\n","      <td>0.50</td>\n","      <td>1.54</td>\n","      <td>0.95</td>\n","      <td>1.07</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.07</td>\n","      <td>1.14</td>\n","      <td>0.64</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.96</td>\n","      <td>0.10</td>\n","      <td>2.46</td>\n","      <td>0.56</td>\n","      <td>0.00</td>\n","      <td>1.07</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.34</td>\n","      <td>0.00</td>\n","      <td>0.31</td>\n","      <td>0.12</td>\n","      <td>0.43</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.06</td>\n","      <td>0.00</td>\n","      <td>2.39</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.17</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.85</td>\n","      <td>0.48</td>\n","      <td>0.88</td>\n","      <td>0.16</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.28</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.34</td>\n","      <td>0.33</td>\n","      <td>0.11</td>\n","      <td>0.50</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.09</td>\n","      <td>1.21</td>\n","      <td>0.65</td>\n","      <td>0.60</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.14</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1.77</td>\n","      <td>2.40</td>\n","      <td>1.87</td>\n","      <td>1.89</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.05</td>\n","      <td>0.00</td>\n","      <td>0.02</td>\n","      <td>0.68</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.82</td>\n","      <td>0.11</td>\n","      <td>0.00</td>\n","      <td>0.27</td>\n","      <td>0.34</td>\n","      <td>1.29</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.16</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.99</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>1.50</td>\n","      <td>0.21</td>\n","      <td>4.79</td>\n","      <td>0.03</td>\n","      <td>1.28</td>\n","      <td>2.88</td>\n","      <td>1.68</td>\n","      <td>2.04</td>\n","      <td>0.08</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.98</td>\n","      <td>0.85</td>\n","      <td>0.66</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>1.37</td>\n","      <td>0.00</td>\n","      <td>2.26</td>\n","      <td>1.67</td>\n","      <td>0.79</td>\n","      <td>1.93</td>\n","      <td>1.09</td>\n","      <td>0.86</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.17</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.36</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>1.60</td>\n","      <td>1.26</td>\n","      <td>1.30</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.36</td>\n","      <td>0.00</td>\n","      <td>0.91</td>\n","      <td>0.52</td>\n","      <td>0.00</td>\n","      <td>0.78</td>\n","      <td>0.41</td>\n","      <td>0.43</td>\n","      <td>0.00</td>\n","      <td>0.64</td>\n","      <td>0.00</td>\n","      <td>0.35</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.08</td>\n","      <td>0.00</td>\n","      <td>3.66</td>\n","      <td>0.93</td>\n","      <td>0.65</td>\n","      <td>2.13</td>\n","      <td>0.67</td>\n","      <td>0.11</td>\n","      <td>0.43</td>\n","      <td>0.48</td>\n","      <td>0.12</td>\n","      <td>0.92</td>\n","      <td>0.60</td>\n","      <td>0.71</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.85</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.25</td>\n","      <td>0.62</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.12</td>\n","      <td>0.08</td>\n","      <td>0.43</td>\n","      <td>0.00</td>\n","      <td>1.22</td>\n","      <td>0.84</td>\n","      <td>0.21</td>\n","      <td>0.03</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.92</td>\n","      <td>0.00</td>\n","      <td>0.10</td>\n","      <td>1.38</td>\n","      <td>0.70</td>\n","      <td>0.02</td>\n","      <td>0.00</td>\n","      <td>0.74</td>\n","      <td>0.24</td>\n","      <td>0.57</td>\n","      <td>1.81</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>1.30</td>\n","      <td>0.00</td>\n","      <td>3.04</td>\n","      <td>0.22</td>\n","      <td>0.18</td>\n","      <td>1.77</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.27</td>\n","      <td>1.44</td>\n","      <td>0.61</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.93</td>\n","      <td>0.00</td>\n","      <td>1.55</td>\n","      <td>4.16</td>\n","      <td>3.78</td>\n","      <td>1.00</td>\n","      <td>0.70</td>\n","      <td>0.88</td>\n","      <td>0.23</td>\n","      <td>1.28</td>\n","      <td>0.80</td>\n","      <td>0.52</td>\n","      <td>0.53</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.10</td>\n","      <td>0.00</td>\n","      <td>2.68</td>\n","      <td>0.00</td>\n","      <td>1.65</td>\n","      <td>2.64</td>\n","      <td>3.02</td>\n","      <td>2.34</td>\n","      <td>0.00</td>\n","      <td>1.49</td>\n","      <td>1.93</td>\n","      <td>2.66</td>\n","      <td>0.08</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.54</td>\n","      <td>0.00</td>\n","      <td>frown</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.76</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.29</td>\n","      <td>2.62</td>\n","      <td>1.03</td>\n","      <td>0.24</td>\n","      <td>2.74</td>\n","      <td>3.14</td>\n","      <td>3.10</td>\n","      <td>0.00</td>\n","      <td>0.04</td>\n","      <td>0.00</td>\n","      <td>0.39</td>\n","      <td>2.48</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>1.67</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.43</td>\n","      <td>3.44</td>\n","      <td>1.65</td>\n","      <td>0.27</td>\n","      <td>2.35</td>\n","      <td>3.23</td>\n","      <td>2.72</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.23</td>\n","      <td>0.00</td>\n","      <td>3.47</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.57</td>\n","      <td>2.71</td>\n","      <td>1.42</td>\n","      <td>0.68</td>\n","      <td>2.17</td>\n","      <td>2.90</td>\n","      <td>1.75</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.12</td>\n","      <td>2.72</td>\n","      <td>0.26</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>3.35</td>\n","      <td>2.52</td>\n","      <td>1.24</td>\n","      <td>2.39</td>\n","      <td>3.39</td>\n","      <td>1.02</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.10</td>\n","      <td>0.00</td>\n","      <td>2.28</td>\n","      <td>0.00</td>\n","      <td>0.32</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.42</td>\n","      <td>0.00</td>\n","      <td>2.22</td>\n","      <td>0.00</td>\n","      <td>3.20</td>\n","      <td>1.47</td>\n","      <td>1.32</td>\n","      <td>3.54</td>\n","      <td>3.46</td>\n","      <td>2.20</td>\n","      <td>0.00</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>0.04</td>\n","      <td>2.82</td>\n","      <td>0.28</td>\n","      <td>0.39</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.27</td>\n","      <td>0.59</td>\n","      <td>0.00</td>\n","      <td>1.08</td>\n","      <td>0.40</td>\n","      <td>0.58</td>\n","      <td>0.92</td>\n","      <td>1.53</td>\n","      <td>2.80</td>\n","      <td>0.25</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.09</td>\n","      <td>0.23</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>1.10</td>\n","      <td>1.32</td>\n","      <td>0.58</td>\n","      <td>0.10</td>\n","      <td>3.92</td>\n","      <td>2.38</td>\n","      <td>2.13</td>\n","      <td>3.53</td>\n","      <td>4.27</td>\n","      <td>4.21</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.43</td>\n","      <td>0.00</td>\n","      <td>5.00</td>\n","      <td>1.26</td>\n","      <td>0.35</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.06</td>\n","      <td>0.00</td>\n","      <td>0.18</td>\n","      <td>0.00</td>\n","      <td>3.07</td>\n","      <td>3.62</td>\n","      <td>0.25</td>\n","      <td>2.24</td>\n","      <td>2.86</td>\n","      <td>1.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.26</td>\n","      <td>0.00</td>\n","      <td>3.25</td>\n","      <td>0.95</td>\n","      <td>0.18</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.38</td>\n","      <td>2.17</td>\n","      <td>1.84</td>\n","      <td>0.00</td>\n","      <td>1.52</td>\n","      <td>3.50</td>\n","      <td>1.57</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.25</td>\n","      <td>0.20</td>\n","      <td>2.18</td>\n","      <td>0.22</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.13</td>\n","      <td>2.41</td>\n","      <td>2.31</td>\n","      <td>0.38</td>\n","      <td>1.90</td>\n","      <td>3.16</td>\n","      <td>1.63</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.01</td>\n","      <td>0.00</td>\n","      <td>2.52</td>\n","      <td>1.01</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.93</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.12</td>\n","      <td>0.97</td>\n","      <td>0.00</td>\n","      <td>1.24</td>\n","      <td>3.37</td>\n","      <td>1.96</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.62</td>\n","      <td>0.03</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1.17</td>\n","      <td>0.00</td>\n","      <td>0.87</td>\n","      <td>1.43</td>\n","      <td>3.35</td>\n","      <td>2.65</td>\n","      <td>0.10</td>\n","      <td>2.19</td>\n","      <td>3.98</td>\n","      <td>0.92</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.14</td>\n","      <td>0.00</td>\n","      <td>3.04</td>\n","      <td>0.40</td>\n","      <td>0.22</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.33</td>\n","      <td>0.00</td>\n","      <td>0.11</td>\n","      <td>0.00</td>\n","      <td>1.88</td>\n","      <td>2.28</td>\n","      <td>1.14</td>\n","      <td>3.64</td>\n","      <td>1.43</td>\n","      <td>1.08</td>\n","      <td>0.46</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.52</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.33</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.36</td>\n","      <td>1.14</td>\n","      <td>0.00</td>\n","      <td>0.56</td>\n","      <td>2.25</td>\n","      <td>1.40</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.50</td>\n","      <td>0.00</td>\n","      <td>1.05</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.70</td>\n","      <td>1.93</td>\n","      <td>0.59</td>\n","      <td>0.00</td>\n","      <td>0.48</td>\n","      <td>3.29</td>\n","      <td>0.91</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.27</td>\n","      <td>0.00</td>\n","      <td>2.70</td>\n","      <td>0.83</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.51</td>\n","      <td>0.06</td>\n","      <td>0.35</td>\n","      <td>0.91</td>\n","      <td>3.51</td>\n","      <td>2.36</td>\n","      <td>0.00</td>\n","      <td>2.39</td>\n","      <td>4.00</td>\n","      <td>1.17</td>\n","      <td>0.03</td>\n","      <td>0.00</td>\n","      <td>0.41</td>\n","      <td>0.27</td>\n","      <td>3.24</td>\n","      <td>1.17</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.83</td>\n","      <td>1.14</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>1.32</td>\n","      <td>1.29</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.30</td>\n","      <td>0.10</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>1.56</td>\n","      <td>1.35</td>\n","      <td>0.00</td>\n","      <td>1.40</td>\n","      <td>2.78</td>\n","      <td>1.76</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>2.18</td>\n","      <td>0.26</td>\n","      <td>0.00</td>\n","      <td>smile</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      AU01_r    AU02_r    AU04_r    AU05_r    AU06_r    AU07_r    AU09_r  \\\n","0       0.00      0.00      1.83      2.59      0.00      0.92      0.00   \n","1       0.00      0.00      1.83      0.05      0.00      0.00      0.05   \n","2       0.00      0.22      1.52      1.20      0.57      0.00      0.71   \n","3       0.00      0.00      1.44      0.00      0.50      1.54      0.95   \n","4       0.96      0.10      2.46      0.56      0.00      1.07      0.00   \n","5       0.06      0.00      2.39      0.00      0.00      2.17      0.00   \n","6       0.34      0.33      0.11      0.50      0.00      0.00      0.00   \n","7       1.77      2.40      1.87      1.89      0.00      0.00      0.00   \n","8       0.00      0.00      2.82      0.11      0.00      0.27      0.34   \n","9       1.50      0.21      4.79      0.03      1.28      2.88      1.68   \n","10      1.37      0.00      2.26      1.67      0.79      1.93      1.09   \n","11      1.60      1.26      1.30      0.00      0.00      0.36      0.00   \n","12      0.08      0.00      3.66      0.93      0.65      2.13      0.67   \n","13      0.00      0.00      2.25      0.62      0.00      0.00      0.12   \n","14      0.00      0.00      1.92      0.00      0.10      1.38      0.70   \n","15      1.30      0.00      3.04      0.22      0.18      1.77      0.00   \n","16      0.00      0.00      0.93      0.00      1.55      4.16      3.78   \n","17      0.10      0.00      2.68      0.00      1.65      2.64      3.02   \n","18      0.76      0.00      0.00      0.29      2.62      1.03      0.24   \n","19      1.67      0.00      0.00      0.43      3.44      1.65      0.27   \n","20      0.00      0.00      0.00      0.57      2.71      1.42      0.68   \n","21      0.00      0.00      0.00      0.00      3.35      2.52      1.24   \n","22      0.42      0.00      2.22      0.00      3.20      1.47      1.32   \n","23      0.27      0.59      0.00      1.08      0.40      0.58      0.92   \n","24      1.10      1.32      0.58      0.10      3.92      2.38      2.13   \n","25      0.06      0.00      0.18      0.00      3.07      3.62      0.25   \n","26      0.00      0.00      0.00      0.38      2.17      1.84      0.00   \n","27      0.00      0.00      0.00      0.13      2.41      2.31      0.38   \n","28      0.93      0.00      0.00      0.00      2.12      0.97      0.00   \n","29      1.17      0.00      0.87      1.43      3.35      2.65      0.10   \n","30      0.33      0.00      0.11      0.00      1.88      2.28      1.14   \n","31      0.33      0.00      0.00      0.00      1.36      1.14      0.00   \n","32      0.00      0.00      0.00      0.70      1.93      0.59      0.00   \n","33      0.51      0.06      0.35      0.91      3.51      2.36      0.00   \n","34      0.00      0.00      0.00      0.00      0.83      1.14      0.01   \n","35      0.00      0.00      0.00      0.00      1.56      1.35      0.00   \n","\n","      AU10_r    AU12_r    AU14_r    AU15_r    AU17_r    AU20_r    AU23_r  \\\n","0       1.21      0.00      0.15      1.37      2.53      0.00      0.45   \n","1       0.84      0.00      1.30      2.05      2.07      2.07      0.94   \n","2       1.28      0.00      0.00      1.66      0.20      0.00      0.19   \n","3       1.07      0.00      0.00      1.07      1.14      0.64      0.00   \n","4       0.00      0.00      0.00      0.00      0.00      0.34      0.00   \n","5       0.00      0.00      0.00      1.85      0.48      0.88      0.16   \n","6       0.00      0.00      0.09      1.21      0.65      0.60      0.00   \n","7       0.05      0.00      0.02      0.68      0.00      0.00      0.00   \n","8       1.29      0.00      0.00      0.16      0.00      0.00      0.00   \n","9       2.04      0.08      0.00      0.00      0.00      0.00      0.00   \n","10      0.86      0.00      0.00      1.17      0.00      0.00      0.00   \n","11      0.91      0.52      0.00      0.78      0.41      0.43      0.00   \n","12      0.11      0.43      0.48      0.12      0.92      0.60      0.71   \n","13      0.08      0.43      0.00      1.22      0.84      0.21      0.03   \n","14      0.02      0.00      0.74      0.24      0.57      1.81      0.00   \n","15      0.00      0.00      0.00      1.27      1.44      0.61      0.00   \n","16      1.00      0.70      0.88      0.23      1.28      0.80      0.52   \n","17      2.34      0.00      1.49      1.93      2.66      0.08      0.00   \n","18      2.74      3.14      3.10      0.00      0.04      0.00      0.39   \n","19      2.35      3.23      2.72      0.00      0.00      0.23      0.00   \n","20      2.17      2.90      1.75      0.00      0.00      0.00      0.12   \n","21      2.39      3.39      1.02      0.00      0.00      0.10      0.00   \n","22      3.54      3.46      2.20      0.00      0.01      0.00      0.04   \n","23      1.53      2.80      0.25      0.00      0.00      0.00      0.00   \n","24      3.53      4.27      4.21      0.00      0.00      0.43      0.00   \n","25      2.24      2.86      1.38      0.00      0.00      0.26      0.00   \n","26      1.52      3.50      1.57      0.00      0.00      1.25      0.20   \n","27      1.90      3.16      1.63      0.00      0.00      1.01      0.00   \n","28      1.24      3.37      1.96      0.00      0.00      0.00      0.00   \n","29      2.19      3.98      0.92      0.00      0.00      1.14      0.00   \n","30      3.64      1.43      1.08      0.46      0.00      0.00      0.00   \n","31      0.56      2.25      1.40      0.00      0.00      0.50      0.00   \n","32      0.48      3.29      0.91      0.00      0.00      0.27      0.00   \n","33      2.39      4.00      1.17      0.03      0.00      0.41      0.27   \n","34      0.00      1.32      1.29      0.00      0.00      0.30      0.10   \n","35      1.40      2.78      1.76      0.00      0.00      0.00      0.00   \n","\n","      AU25_r    AU26_r    AU45_r  Class  \n","0       0.00      0.00      0.00  frown  \n","1       0.00      1.00      0.00  frown  \n","2       0.00      0.00      0.00  frown  \n","3       0.00      0.00      0.00  frown  \n","4       0.31      0.12      0.43  frown  \n","5       0.00      0.00      1.28  frown  \n","6       0.00      0.00      0.14  frown  \n","7       0.00      0.00      0.00  frown  \n","8       0.99      0.00      0.00  frown  \n","9       2.98      0.85      0.66  frown  \n","10      0.36      0.01      0.00  frown  \n","11      0.64      0.00      0.35  frown  \n","12      0.00      0.00      0.85  frown  \n","13      0.00      0.00      0.00  frown  \n","14      0.00      0.00      0.00  frown  \n","15      0.00      0.00      0.00  frown  \n","16      0.53      0.00      0.00  frown  \n","17      0.00      0.54      0.00  frown  \n","18      2.48      0.00      0.00  smile  \n","19      3.47      0.00      0.00  smile  \n","20      2.72      0.26      0.00  smile  \n","21      2.28      0.00      0.32  smile  \n","22      2.82      0.28      0.39  smile  \n","23      2.09      0.23      0.00  smile  \n","24      5.00      1.26      0.35  smile  \n","25      3.25      0.95      0.18  smile  \n","26      2.18      0.22      0.00  smile  \n","27      2.52      1.01      0.00  smile  \n","28      2.62      0.03      0.00  smile  \n","29      3.04      0.40      0.22  smile  \n","30      2.52      0.00      0.00  smile  \n","31      1.05      0.00      0.00  smile  \n","32      2.70      0.83      0.00  smile  \n","33      3.24      1.17      0.00  smile  \n","34      0.00      0.00      0.00  smile  \n","35      2.18      0.26      0.00  smile  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["train_data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["array(['frown', 'frown', 'frown', 'frown', 'frown', 'frown', 'frown',\n","       'frown', 'smile', 'smile', 'smile', 'smile', 'smile', 'smile',\n","       'smile', 'smile'], dtype=object)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["test_classes"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.34, 0.44, 1.13, 0.18, 1.87, 3.55, 4.08, 1.35, 0.  , 0.54, 0.8 ,\n","        1.89, 0.  , 0.96, 0.74, 1.71, 0.57],\n","       [0.74, 0.  , 1.34, 0.  , 1.1 , 2.8 , 2.64, 1.35, 0.  , 0.2 , 0.8 ,\n","        0.  , 0.57, 0.34, 0.75, 0.27, 0.  ],\n","       [0.75, 0.07, 2.87, 0.02, 0.86, 1.34, 0.96, 1.68, 0.19, 1.14, 1.23,\n","        1.22, 0.  , 0.  , 0.84, 0.  , 0.  ],\n","       [0.15, 0.24, 2.79, 0.21, 0.79, 3.  , 0.36, 1.58, 0.  , 0.78, 1.14,\n","        1.36, 0.46, 0.17, 0.45, 0.99, 1.67],\n","       [1.05, 0.31, 3.95, 1.49, 2.27, 3.09, 2.3 , 3.43, 0.88, 1.27, 0.  ,\n","        0.  , 1.68, 0.  , 3.03, 1.04, 0.  ],\n","       [1.48, 0.83, 2.3 , 0.73, 0.61, 2.97, 0.76, 0.57, 0.  , 0.  , 0.17,\n","        0.66, 1.39, 0.  , 0.  , 0.  , 0.  ],\n","       [0.  , 0.  , 2.26, 0.53, 0.  , 0.85, 0.  , 0.  , 0.  , 0.  , 0.  ,\n","        0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n","       [0.07, 0.  , 1.87, 0.02, 0.38, 2.52, 0.  , 0.  , 0.54, 0.46, 0.  ,\n","        0.  , 0.46, 0.04, 0.53, 0.38, 0.  ],\n","       [0.  , 0.  , 0.  , 0.  , 1.55, 2.61, 0.  , 0.08, 2.25, 1.  , 0.  ,\n","        0.  , 1.24, 0.01, 1.2 , 1.02, 0.  ],\n","       [0.72, 0.  , 0.6 , 0.43, 2.63, 1.22, 0.01, 2.26, 3.06, 1.89, 0.  ,\n","        0.  , 0.  , 0.  , 2.96, 0.  , 0.  ],\n","       [0.  , 0.  , 0.17, 0.  , 3.94, 4.35, 0.29, 2.97, 4.  , 1.65, 0.  ,\n","        0.  , 0.  , 0.38, 3.1 , 0.09, 0.  ],\n","       [0.  , 0.  , 0.  , 0.31, 3.48, 3.48, 1.25, 3.22, 3.85, 1.82, 0.  ,\n","        0.  , 0.32, 0.03, 2.95, 1.14, 0.  ],\n","       [1.48, 0.77, 0.  , 0.56, 2.11, 0.  , 0.05, 2.42, 2.99, 3.83, 0.  ,\n","        0.1 , 0.83, 0.3 , 1.66, 0.65, 0.  ],\n","       [0.  , 0.  , 0.  , 0.  , 1.66, 0.83, 0.39, 2.54, 2.66, 0.25, 0.  ,\n","        0.  , 0.  , 0.91, 1.59, 0.  , 0.  ],\n","       [1.45, 0.  , 0.05, 0.  , 3.81, 4.18, 0.17, 2.74, 3.27, 1.03, 0.19,\n","        0.43, 0.41, 0.84, 0.  , 0.85, 0.65],\n","       [0.2 , 0.  , 0.  , 0.  , 1.86, 1.5 , 0.  , 1.31, 2.91, 1.5 , 0.  ,\n","        0.  , 0.49, 0.09, 1.97, 1.24, 0.  ]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["test_features"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error Rate: 1.0\n","Confusion Matrix:\n","Predicted  0  1\n","Actual         \n","frown      8  0\n","smile      4  4\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","# Step 1: Load the training and test data\n","train_data = pd.read_csv(\"training-part-2.csv\")\n","test_data = pd.read_csv(\"test-part-2.csv\")\n","\n","# Step 2: Separate the feature vectors and classes\n","train_features = train_data.iloc[:, :-1].values\n","train_classes = train_data.iloc[:, -1].values\n","test_features = test_data.iloc[:, :-1].values\n","test_classes = test_data.iloc[:, -1].values\n","\n","# Step 3: Calculate class priors\n","class_priors = {}\n","for class_label in np.unique(train_classes):\n","    class_priors[class_label] = np.mean(train_classes == class_label)\n","\n","# Step 4: Calculate mean vectors and covariance matrices\n","class_means = {}\n","class_covs = {}\n","for class_label in np.unique(train_classes):\n","    class_features = train_features[train_classes == class_label]\n","    class_means[class_label] = np.mean(class_features, axis=0)\n","    class_covs[class_label] = np.cov(class_features, rowvar=False)\n","\n","# Step 5: Implement Gaussian Discriminant Function\n","def gaussian_discriminant_function(x, class_label):\n","    mean = class_means[class_label]\n","    cov = class_covs[class_label]\n","    det = np.linalg.det(cov)\n","    inv = np.linalg.inv(cov)\n","    exponent = -0.5 * np.dot(np.dot((x - mean).T, inv), (x - mean))\n","    return 1 / (np.sqrt((2 * np.pi) ** len(mean) * det)) * np.exp(exponent)\n","\n","# Step 6: Classify test data using Gaussian Discriminant Function\n","predicted_classes = []\n","for test_feature in test_features:\n","    probabilities = []\n","    for class_label in np.unique(train_classes):\n","        probability = gaussian_discriminant_function(test_feature, class_label) * class_priors[class_label]\n","        probabilities.append(probability)\n","    predicted_class = np.argmax(probabilities)\n","    predicted_classes.append(predicted_class)\n","\n","# Step 7: Calculate error rate\n","error_rate = np.mean(predicted_classes != test_classes)\n","\n","# Step 8: Calculate confusion matrix\n","# Print results\n","print(\"Error Rate:\", error_rate)\n","print(\"Confusion Matrix:\")\n","print(pd.crosstab(pd.Series(test_classes, name='Actual'), pd.Series(predicted_classes, name='Predicted')))\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0., 0.],\n","       [0., 0.]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["conf_matrix "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Step 3: Calculate class priors\n","class_priors = {}\n","for class_label in np.unique(train_classes):\n","    class_priors[class_label] = np.mean(train_classes == class_label)\n","\n","# Step 4: Calculate mean vectors and covariance matrices\n","class_means = {}\n","class_covs = {}\n","for class_label in np.unique(train_classes):\n","    class_features = train_features[train_classes == class_label]\n","    class_means[class_label] = np.mean(class_features, axis=0)\n","    class_covs[class_label] = np.cov(class_features, rowvar=False)\n","\n","# Step 5: Implement Gaussian Discriminant Function\n","def gaussian_discriminant_function(x, class_label):\n","    mean = class_means[class_label]\n","    cov = class_covs[class_label]\n","    det = np.linalg.det(cov)\n","    inv = np.linalg.inv(cov)\n","    exponent = -0.5 * np.dot(np.dot((x - mean).T, inv), (x - mean))\n","    return 1 / (np.sqrt((2 * np.pi) ** len(mean) * det)) * np.exp(exponent)\n","\n","# Step 6: Classify test data using Gaussian Discriminant Function\n","predicted_classes = []\n","for test_feature in test_features:\n","    probabilities = []\n","    for class_label in np.unique(train_classes):\n","        probability = gaussian_discriminant_function(test_feature, class_label) * class_priors[class_label]\n","        probabilities.append(probability)\n","    predicted_class = np.argmax(probabilities)\n","    predicted_classes.append(predicted_class)\n","\n","# Step 7: Calculate error rate\n","error_rate = np.mean(predicted_classes != test_classes)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["1.0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["error_rate"]},{"cell_type":"markdown","metadata":{},"source":["# TES"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error Rate: 0.0\n","Confusion Matrix:\n","[[8 0]\n"," [0 8]]\n"]}],"source":["import pandas as pd\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Load data\n","train_data = pd.read_csv(\"training-part-2.csv\")\n","test_data = pd.read_csv(\"test-part-2.csv\")\n","\n","# Extract features and labels\n","X_train = train_data.iloc[:, :-1]\n","y_train = train_data.iloc[:, -1]\n","X_test = test_data.iloc[:, :-1]\n","y_test = test_data.iloc[:, -1]\n","\n","# Initialize and fit the Gaussian Discriminant Analysis model\n","lda = LinearDiscriminantAnalysis()\n","lda.fit(X_train, y_train)\n","\n","# Predict classes for the test set\n","y_pred = lda.predict(X_test)\n","\n","# Evaluate the model\n","error_rate = 1 - accuracy_score(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Print results\n","print(\"Error Rate:\", error_rate)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error Rate: 37.5\n"]}],"source":["import pandas as pd\n","\n","# Load data\n","train_data = pd.read_csv(\"training-part-2.csv\")\n","test_data = pd.read_csv(\"test-part-2.csv\")\n","\n","# Calculate the sum of feature values for each class in the training set\n","sum_smile = train_data[train_data['Class'] == 'smile'].iloc[:, :-1].sum(axis=1).mean()\n","sum_frown = train_data[train_data['Class'] == 'frown'].iloc[:, :-1].sum(axis=1).mean()\n","\n","# Classify instances in the test set based on the sum of feature values\n","predictions = []\n","for index, row in test_data.iterrows():\n","    sum_features = row.iloc[:-1].sum()\n","    predicted_class = 'smile' if abs(sum_features - sum_smile) < abs(sum_features - sum_frown) else 'frown'\n","    predictions.append(predicted_class)\n","\n","# Evaluate the model\n","correct_predictions = (predictions == test_data['Class']).sum()\n","total_instances = len(test_data)\n","error_rate = (1 - (correct_predictions / total_instances))*100\n","\n","# Print results\n","print(\"Error Rate:\", error_rate)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Error Rate: 6.25\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load data\n","train_data = pd.read_csv(\"training-part-2.csv\")\n","test_data = pd.read_csv(\"test-part-2.csv\")\n","\n","# Extract features and labels\n","X_train = train_data.iloc[:, :-1]\n","y_train = train_data.iloc[:, -1]\n","X_test = test_data.iloc[:, :-1]\n","y_test = test_data.iloc[:, -1]\n","\n","# Calculate Class Prior Probabilities\n","prior_smile = np.sum(y_train == 'smile') / len(y_train)\n","prior_frown = np.sum(y_train == 'frown') / len(y_train)\n","\n","# Calculate Class Means\n","mean_smile = X_train[y_train == 'smile'].mean()\n","mean_frown = X_train[y_train == 'frown'].mean()\n","\n","# Calculate Class Covariance Matrices\n","cov_smile = np.cov(X_train[y_train == 'smile'].T)\n","cov_frown = np.cov(X_train[y_train == 'frown'].T)\n","\n","# Gaussian Discriminant Function\n","def gaussian_discriminant_function(x, mean, cov, prior):\n","    exponent = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean))\n","    return exponent - 0.5 * np.log(np.linalg.det(cov)) + np.log(prior)\n","\n","# Classify Test Set\n","predictions = []\n","for i in range(len(X_test)):\n","    x = X_test.iloc[i, :]\n","    g_smile = gaussian_discriminant_function(x, mean_smile, cov_smile, prior_smile)\n","    g_frown = gaussian_discriminant_function(x, mean_frown, cov_frown, prior_frown)\n","\n","    predicted_class = 'smile' if g_smile > g_frown else 'frown'\n","    predictions.append(predicted_class)\n","\n","# Evaluate\n","misclassifications = np.sum(predictions != y_test)\n","error_rate = (misclassifications / len(y_test))*100\n","print(\"Error Rate:\", error_rate)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPY5UERNCC0HKDBWF5OmFnf","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
